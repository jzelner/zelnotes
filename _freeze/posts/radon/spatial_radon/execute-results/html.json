{
  "hash": "ebc9056c486456459643f4c80dadb3c5",
  "result": {
    "markdown": "---\npagetitle: Taking a spatial perspective on the `radon` data\nauthor: Jon Zelner\ndate: \"2/23/2022\"\ndraft: true\n---\n\n::: {.cell}\n\n:::\n\n\n# Taking a more-spatial perspective on the `radon` data\n\nThis tutorial is a follow-up to a prior exercise using these data. So if you haven't already, please go back and take a look at the original multi-level modeling radon example [here](/posts/radon/index.html).\n\nIn order to work with these data, we'll first need to merge the original radon measurements into a shapefile for the state of Minnesota so that we can visualize and analyze spatial patterning of our key exposure of interest (soil uranium) as well as the outcome of interest, i.e. household-level radon, as well as indicators of goodness-of-fit including the model residuals.\n\n## Data Preparation\n\n### Download a shapefile for Minnesota\n\nFirst, we need to get a shapefile for the state of Minnesota in which each polygon represents an individual county. Thankfully, in R, this is made easy using the excellent `tidycensus` package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(tigris_use_cache = TRUE)\n\nminnesota <- get_acs(\n  state = \"MN\",\n  geography = \"county\",\n  variables = \"B19013_001\",\n  geometry = TRUE,\n  year = 2020\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nGetting data from the 2016-2020 5-year ACS\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: • You have not set a Census API key. Users without a key are limited to 500\nqueries per day and may experience performance limitations.\nℹ For best results, get a Census API key at http://api.census.gov/data/\nkey_signup.html and then supply the key to the `census_api_key()` function to\nuse it throughout your tidycensus session.\nThis warning is displayed once per session.\n```\n:::\n:::\n\n\nTidycensus gives us the data as an `sf` dataframe containing a number of fields including population estimates, which we can plot straightforwardly using the `plot` function supplied by the `sf` package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(minnesota[\"estimate\"])\n```\n\n::: {.cell-output-display}\n![](spatial_radon_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n### Merge the spatial data with the radon data\n\nIn its raw form, this spatial dataset isn't quite ready to merge with the radon data. If we take a peek at the county names in the shapefile, we can see that they don't quite match the formatting of the ones in the original data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(sort(minnesota$NAME))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Aitkin County, Minnesota\"    \"Anoka County, Minnesota\"    \n[3] \"Becker County, Minnesota\"    \"Beltrami County, Minnesota\" \n[5] \"Benton County, Minnesota\"    \"Big Stone County, Minnesota\"\n```\n:::\n:::\n\n\nWhereas in the radon data we see:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(unique(as.character(radon$county)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AITKIN\"   \"ANOKA\"    \"BECKER\"   \"BELTRAMI\" \"BENTON\"   \"BIGSTONE\"\n```\n:::\n:::\n\n\nThe big differences here are that the shapefile uses: 1) mixed-case county names and 2) includes the name of the state in each label. To make these match the `radon` dataset, we can use some tools from the `stringr` package as well as some base R functions: \n\n::: {.cell}\n\n```{.r .cell-code}\nminnesota <-\n  minnesota %>% mutate(\n    ## Since all of the original county names have the same substring \" County, Minnesota\"\n    ## we can use the str_remove function to pull them out of all of them\n    county = str_remove(NAME, \" County, Minnesota\") %>% \n      ## Since some of the counties  officially have two-word names (e.g. Big Stone)\n      ## which are collapsed in the radon dataset, we will use this function to remove all spaces:\n      str_replace_all(\" \", \"\") %>% \n      ## A few county names include abbreviations indicated by the presence of a '.' (e.g. St. Louis)\n      ## so we will get rid of that bit of punctuation since it is not in the original data\n      str_replace_all(\"\\\\.\", \"\") %>% \n      ## Finally, convert all the county names to uppercase\n      toupper()\n  )\n```\n:::\n\nNow, the county labels should match:\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(sort(minnesota$county))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AITKIN\"   \"ANOKA\"    \"BECKER\"   \"BELTRAMI\" \"BENTON\"   \"BIGSTONE\"\n```\n:::\n:::\n\n\n### Preparing the `radon` dataset\n\nWe will repeat the steps from the earlier tutorial in order to prepare our data for analysis:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nradon <- radon %>% mutate(basement = 1 - floor)\n\ncounty_uranium <- radon %>%\n  group_by(county) %>%\n  summarize(log_uranium = first(log_uranium), \n            median_radon = median(log_radon))\n```\n:::\n\n\nBecause the sf dataset returned by tidycensus is a dataframe, we can then easily merge the county-level soil uranium concentrations we derived above into the shapefile. We use the `left_join` function from `dplyr` to ensure that all of the counties in the original shapefile are represented in the final dataset, even if a soil uranium measure is unavailable for them in the original data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nminnesota_radon <- left_join(minnesota, county_uranium)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(county)`\n```\n:::\n:::\n\n\nWe can then plot the log-uranium measures on the map and see that, in fact, they are quite spatially correlated. We can also see that there appear to be two counties which are missing soil uranium data in the `radon` dataset:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(minnesota_radon[\"log_uranium\"])\n```\n\n::: {.cell-output-display}\n![](spatial_radon_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nTo validate our hunch that soil uranium is spatially concentrated in Minnesota, we can calculate the value of Moran's I for these data using some functions from the `spdep` package. First, we use the `poly2nb` function to obtain the neighbors for each polygon, which will be used to calculate Moran's I.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nnb <- poly2nb(minnesota_radon)\n```\n:::\n\n\nThis function yields an R list in which each entry is a vector with the indices for the neighbors of the i-th county. For example, this prints the neighbors of the first three counties in the dataset:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[1] 12 47\n\n[[2]]\n[1] 27\n\n[[3]]\n[1]  8 24 46 57 67 76 83 87\n```\n:::\n:::\n\n\nWe then pass this function to the `nb2listw` function to obtain weights for the relationships between neighbors. Here, we use the simplest option available, \"B\", for binary weights equal to 1 if the areas are neighbors and 0 otherwise:\n\n::: {.cell}\n\n```{.r .cell-code}\nlw <- nb2listw(nb, style=\"B\", zero.policy=TRUE)\nprint(lw$weights[1:3])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[1] 1 1\n\n[[2]]\n[1] 1\n\n[[3]]\n[1] 1 1 1 1 1 1 1 1\n```\n:::\n:::\n\n\nFinally, we can pass these weights, along with some additional information including the outcome of interest at each location, the total number of locations, and the sum of all the weights to the `moran` function. The `NAOK=TRUE` option used here also allows the function to drop locations where data are missing:\n\n::: {.cell}\n\n```{.r .cell-code}\nradon_i <- moran(minnesota_radon$log_uranium, lw, length(nb), Szero(lw),NAOK=TRUE)$I\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in lag.listw(listw, z, zero.policy = zero.policy, NAOK = NAOK): NAs in\nlagged values\n```\n:::\n:::\n\n\nWhen we do this, we find that the value of Moran's I = 0.71, which is close to the maximum value of 1. Since we'll be returning to the calculation of Moran's I using our spatial data, lets pack it up into a function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmoranFromSF <- function(x, sfdf, style=\"B\") {\n  nb <- poly2nb(sfdf)\n  lw <- nb2listw(nb, style=style, zero.policy=TRUE)\n  mi <- moran(x, lw, length(nb), Szero(lw), NAOK=TRUE)$I\n  return(mi)\n}\n\nprint(moranFromSF(minnesota_radon$log_uranium, minnesota_radon))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.712615\n```\n:::\n:::\n\n\nOf course, our key quantity of interest isn't soil uranium but the concentration of radon at the household level. When we constructed the `county_uranium` dataset above, we also calculated the median radon concentration in the data for each county. When we plot it, we see something similar to the soil uranium, but perhaps a bit less clear:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(minnesota_radon[\"median_radon\"])\n```\n\n::: {.cell-output-display}\n![](spatial_radon_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nUsing our function for computing Moran's I, we can easily go ahead and determine how clustered these data are:\n\n::: {.cell}\n\n```{.r .cell-code}\nradon_mi <- moranFromSF(minnesota_radon$median_radon, minnesota_radon)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in lag.listw(listw, z, zero.policy = zero.policy, NAOK = NAOK): NAs in\nlagged values\n```\n:::\n:::\n\n\nWhich comes out to 0.25, which is smaller than the value we got for uranium, but still indicates meaningful clustering. Pause here and take a moment to try to figure out what might account for the difference in this intensity of clustering? \n\n### Testing, testing\n\nOne way to determine whether the spatial aggregation of the radon measurements is meaningful is to compare it to a *counterfactual scenario* in which the distribution of radon concentrations is known to be uncorrelated with space. This assumption, known as complete spatial randomness (or CSR), allows us to provide a benchmark against which we determine whether the value of Moran's I we determined is highly likely to occur by chance alone. Thankfully, it is easy to generate a dataset in which the median radon values are distributed randomly across the map:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Make a new dataset representing 'random minnesota'\nrandom_minnesota <- minnesota_radon\n\n## Use the sample function to resample median radon values without replacement,\n## which yields a vector in which the values of median radon are simply shuffled\n## by county\nrandom_minnesota$median_radon <- sample(minnesota_radon$median_radon, nrow(minnesota_radon), replace = FALSE)\n\n## Plot the new randomized data\nplot(random_minnesota[\"median_radon\"])\n```\n\n::: {.cell-output-display}\n![](spatial_radon_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\nThis yields something that looks pretty randomly distributed, and when we calculate Moran's I, we get a value of -0.08, which is closer to the null value of 0. But this still doesn't tell us anything. What we can do, though, is to generate a bunch of random minnesotas and calculate moran's I for each of those and see how our observed data stack up.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncsrMorans <- function(x, sfdf, trials = 1000, style=\"B\") {\n  nb <- poly2nb(sfdf)\n  lw <- nb2listw(nb, style=style, zero.policy=TRUE)\n  \n  moran_vals <- rep(0, trials)\n  for (i in 1:trials) {\n    random_x <- sample(x, length(x), replace=FALSE)\n    moran_vals[i] <- moran(random_x, lw, length(nb), Szero(lw),NAOK=TRUE)$I\n  }\n  \n  return(moran_vals)\n}  \n\ncsr_dist <- csrMorans(minnesota_radon$log_uranium, minnesota_radon)\n```\n:::\n\n\nThis yields a distribution with a median of 0, and the empirical cdf function shows us the approximate probability of obtaining a value of Moran's greater than or equal to our observed value by random chance alone:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmoran_dist <- ecdf(csr_dist)\nplot(moran_dist)\n```\n\n::: {.cell-output-display}\n![](spatial_radon_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nAnd we can directly estimate this probability as follows:\n\n::: {.cell}\n\n```{.r .cell-code}\nreal_moran <- moranFromSF(minnesota_radon$median_radon, minnesota_radon)\np_moran <- sum(csr_dist >= real_moran)/length(moran_dist)\nprint(p_moran)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n\nFrom 1000 samples, it appears that none of our random datasets yielded a value of Moran's I $\\ge$ to the observed value, suggesting that it is unlikely that we would observe this value as a simple function of sampling variability. \n\n::: {.callout-warning}\n## What could go wrong? \n\nBefore you move on, take a minute to think about what some of the potential flaws in our CSR-nased approach to assessing the meaningfulness or signficance of this result might be.\n:::\n\n### Modeling the radon data",
    "supporting": [
      "spatial_radon_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}