{
  "hash": "13ccd6ed0a8961fe93b88f45eff2761f",
  "result": {
    "markdown": "---\ntitle: \"Taking a spatial perspective on the `radon` data\"\nauthor: \"Jon Zelner\"\ndate: \"3/2/2023\"\nimage: \"minnesota_uranium.png\"\ndraft: false \n---\n\n::: {.cell}\n\n:::\n\n\n\n# Introduction\n\n## Getting Started \n\nThis tutorial is a follow-up to a prior exercise using these data. So if you haven't already, please go back and take a look at the original multi-level modeling radon example [here](/posts/radon/index.html).\n\nTo try this tutorial on your own, download and unzip this [zipfile](spatial_radon.zip) and open up your R or RStudio session in the resulting directory.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(ggplot2)\nlibrary(arm)\nlibrary(tidycensus)\nlibrary(dplyr)\nlibrary(rstanarm)\nlibrary(stringr)\nlibrary(spdep)\nknitr::opts_chunk$set(message = FALSE, warning=FALSE, tidy=TRUE)\n```\n:::\n\n\n## Learning Goals\n\nThe primary goals of this tutorial are to introduce you to:\n\n1. Merging of non-spatial health exposure or outcome data with spatial metadata.\n2. Calculation of important spatial summary statistics, e.g. Moran's I, from such data.\n3. Spatial analysis of residuals from aspatial regression models of spatially-referenced data.\n\n# Data Preparation\n\nBefore diving into the analysis steps, there are several key things we need to do to be able to easily work with these data. \n\n## Download a shapefile for Minnesota\n\nFirst, we need to download a shapefile for the state of Minnesota in which each polygon represents an individual county. Thankfully, in R, this is made easy using the excellent [`tidycensus`](https://walker-data.com/tidycensus/) package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(tigris_use_cache = TRUE)\n\nminnesota <- get_acs(state = \"MN\", geography = \"county\", variables = \"B19013_001\",\n    geometry = TRUE, year = 2020)\n```\n:::\n\n\nTidycensus gives us the data as an [`sf`](https://r-spatial.github.io/sf/) dataframe containing a number of fields including population estimates, which we can plot straightforwardly using the `plot` function supplied by the `sf` package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(minnesota[\"estimate\"])\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n### Merge the spatial data with the radon data\n\nIn its raw form, this spatial dataset isn't quite ready to merge with the radon data. If we take a peek at the county names in the shapefile, we can see that they don't quite match the formatting of the ones in the original data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(sort(minnesota$NAME))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Aitkin County, Minnesota\"    \"Anoka County, Minnesota\"    \n[3] \"Becker County, Minnesota\"    \"Beltrami County, Minnesota\" \n[5] \"Benton County, Minnesota\"    \"Big Stone County, Minnesota\"\n```\n:::\n:::\n\n\nWhereas in the radon data we see:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(unique(as.character(radon$county)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AITKIN\"   \"ANOKA\"    \"BECKER\"   \"BELTRAMI\" \"BENTON\"   \"BIGSTONE\"\n```\n:::\n:::\n\n\nThe big differences here are that the shapefile uses: 1) mixed-case county names and 2) includes the name of the state in each label. To make these match the `radon` dataset, we can use some tools from the `stringr` package as well as some base R functions: \n\n::: {.cell}\n\n```{.r .cell-code}\nminnesota <-\n  minnesota %>% mutate(\n    ## Since all of the original county names have the same substring \" County, Minnesota\"\n    ## we can use the str_remove function to pull them out of all of them\n    county = str_remove(NAME, \" County, Minnesota\") %>% \n      ## Since some of the counties  officially have two-word names (e.g. Big Stone)\n      ## which are collapsed in the radon dataset, we will use this function to remove all spaces:\n      str_replace_all(\" \", \"\") %>% \n      ## A few county names include abbreviations indicated by the presence of a '.' (e.g. St. Louis)\n      ## so we will get rid of that bit of punctuation since it is not in the original data\n      str_replace_all(\"\\\\.\", \"\") %>% \n      ## Finally, convert all the county names to uppercase\n      toupper()\n  )\n```\n:::\n\nNow, the county labels should match:\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(sort(minnesota$county))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"AITKIN\"   \"ANOKA\"    \"BECKER\"   \"BELTRAMI\" \"BENTON\"   \"BIGSTONE\"\n```\n:::\n:::\n\n\n## Preparing the `radon` dataset\n\nWe will repeat the steps from the earlier tutorial in order to prepare our data for analysis:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nradon <- radon %>%\n    mutate(basement = 1 - floor)\n\ncounty_uranium <- radon %>%\n    group_by(county) %>%\n    summarize(log_uranium = first(log_uranium), median_radon = mean(log_radon))\n```\n:::\n\n\nBecause the sf dataset returned by tidycensus is a dataframe, we can then easily merge the county-level soil uranium concentrations we derived above into the shapefile. We use the [`left_join`](https://dplyr.tidyverse.org/reference/mutate-joins.html) function from `dplyr` to ensure that all of the counties in the original shapefile are represented in the final dataset, even if a soil uranium measure is unavailable for them in the original data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nminnesota_radon <- left_join(minnesota, county_uranium)\n```\n:::\n\n\nWe can then plot the log-uranium measures on the map and see that, in fact, they are quite spatially correlated. We can also see that there appear to be two counties which are missing soil uranium data in the `radon` dataset. To have a bit more control over our plots, we'll switch here to using the `geom_sf` function of `ggplot2`, which makes plotting geographies from sf objects easy:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng <- ggplot(minnesota_radon) + geom_sf(aes(fill = log_uranium)) + scale_fill_viridis_c() +\n    ggtitle(\"Soil uranium by MN county\")\nplot(g)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n# Measuring Spatial Correlation\n\nTo validate our hunch that soil uranium is spatially concentrated in Minnesota, we can calculate the value of Moran's I for these data using some functions from the [`spdep`](https://github.com/r-spatial/spdep/) package. First, we use the `poly2nb` function to obtain the neighbors for each polygon, which will be used to calculate Moran's I.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nnb <- poly2nb(minnesota_radon)\n```\n:::\n\n\nThis function yields an R list in which each entry is a vector with the indices for the neighbors of the i-th county. For example, this prints the neighbors of the first three counties in the dataset:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nprint(nb[1:3])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[1] 12 47\n\n[[2]]\n[1] 27\n\n[[3]]\n[1]  8 24 46 57 67 76 83 87\n```\n:::\n:::\n\n\nWe then pass this function to the `nb2listw` function to obtain weights for the relationships between neighbors. Here, we use the simplest option available, \"B\", for binary weights equal to 1 if the areas are neighbors and 0 otherwise:\n\n::: {.cell}\n\n```{.r .cell-code}\nlw <- nb2listw(nb, style = \"B\", zero.policy = TRUE)\nprint(lw$weights[1:3])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[1] 1 1\n\n[[2]]\n[1] 1\n\n[[3]]\n[1] 1 1 1 1 1 1 1 1\n```\n:::\n:::\n\n\nFinally, we can pass these weights, along with some additional information including the outcome of interest at each location, the total number of locations, and the sum of all the weights to the `moran` function. The `NAOK=TRUE` option used here also allows the function to drop locations where data are missing:\n\n::: {.cell}\n\n```{.r .cell-code}\nradon_i <- moran(minnesota_radon$log_uranium, lw, length(nb), Szero(lw), NAOK = TRUE)$I\n```\n:::\n\n\nWhen we do this, we find that the value of Moran's I = 0.71, which is close to the maximum value of 1. Since we'll be returning to the calculation of Moran's I using our spatial data, lets pack it up into a function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmoranFromSF <- function(x, sfdf, style = \"B\") {\n    nb <- poly2nb(sfdf)\n    lw <- nb2listw(nb, style = style, zero.policy = TRUE)\n    mi <- moran(x, lw, length(nb), Szero(lw), NAOK = TRUE)$I\n    return(mi)\n}\n\nprint(moranFromSF(minnesota_radon$log_uranium, minnesota_radon))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.712615\n```\n:::\n:::\n\n\nOf course, our key quantity of interest isn't soil uranium but the concentration of radon at the household level. When we constructed the `county_uranium` dataset above, we also calculated the median radon concentration in the data for each county. When we plot it, we see something similar to the soil uranium, but perhaps a bit less clear:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng <- ggplot(minnesota_radon) + geom_sf(aes(fill = median_radon)) + scale_fill_viridis_c() +\n    ggtitle(paste0(\"Median household radon by MN county (I=\", round(moranFromSF(minnesota_radon$median_radon,\n        minnesota_radon), 2), \")\"))\nplot(g)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nAs you can see in the figure, the value of Moran's I is smaller than we got for log-uranium but still substantial.\n\n:::{.callout-tip}\n## What's going on?\nPause here and take a moment to try to figure out what might account for the difference in this intensity of clustering in radon vs. soil uranium measurements.\n:::\n\n### Testing, testing\n\nOne way to determine whether the spatial aggregation of the radon measurements is meaningful is to compare it to a *counterfactual scenario* in which the distribution of radon concentrations is known to be uncorrelated with space. This assumption, known as complete spatial randomness (or CSR), allows us to provide a benchmark against which we determine whether the value of Moran's I we determined is highly likely to occur by chance alone. Thankfully, it is easy to generate a dataset in which the median radon values are distributed randomly across the map:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Make a new dataset representing 'random minnesota'\nrandom_minnesota <- minnesota_radon\n\n## Use the sample function to resample median radon values without replacement,\n## which yields a vector in which the values of median radon are simply\n## shuffled by county\nrandom_minnesota$median_radon <- sample(minnesota_radon$median_radon, nrow(minnesota_radon),\n    replace = FALSE)\n\n## Plot the new randomized data\ng <- ggplot(random_minnesota) + geom_sf(aes(fill = median_radon)) + scale_fill_viridis_c() +\n    ggtitle(paste0(\"Spatially randomized median radon by MN county (I=\", round(moranFromSF(random_minnesota$median_radon,\n        random_minnesota), 2), \")\"))\nplot(g)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\nThis yields something that looks pretty randomly distributed, which is reflected in a Moran's I estimate closer to the null value of 0. This doesn't necessarily tell us whether this result is meaningful rather than an artifact of random chance.\n\n## Complete Spatial Randomness\n\nWhat we can do, though, is to generate a bunch of random Minnesotas in which there is no relationship between geographic location and median radon, calculate Moran's I for each of those, and see how our observed data stack up.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncsrMorans <- function(x, sfdf, trials = 1000, style = \"B\") {\n    nb <- poly2nb(sfdf)\n    lw <- nb2listw(nb, style = style, zero.policy = TRUE)\n    mv <- moran(x, lw, length(nb), Szero(lw), NAOK = TRUE)$I\n    moran_vals <- rep(0, trials)\n    for (i in 1:trials) {\n        random_x <- sample(x, length(x), replace = FALSE)\n        moran_vals[i] <- moran(random_x, lw, length(nb), Szero(lw), NAOK = TRUE)$I\n    }\n\n    return(list(midist = moran_vals, mi = mv))\n}\n\ncsr_dist <- csrMorans(minnesota_radon$median_radon, minnesota_radon)\n```\n:::\n\n\nWe can use the distribution of Moran's I values taken from the randomized datasets to benchmark how likely our observed value is to occur by purely random chance. The figure below shows that this is quite unlikely:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng <- ggplot() + geom_histogram(aes(x = csr_dist$midist)) + xlab(\"Moran's I value\") +\n    geom_vline(xintercept = csr_dist$mi, colour = \"red\") + ggtitle(\"Randomized values of Moran's I vs. observed for median household radon\")\n\nplot(g)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nAnd we can directly estimate this probability as follows:\n\n::: {.cell}\n\n```{.r .cell-code}\nreal_moran <- moranFromSF(minnesota_radon$median_radon, minnesota_radon)\np_moran <- sum(csr_dist$midist >= csr_dist$mi)/length(csr_dist$midist)\nprint(p_moran)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.001\n```\n:::\n:::\n\n\nFrom 1000 samples, it appears that none of our random datasets yielded a value of Moran's I $\\ge$ to the observed value, suggesting that it is unlikely that we would observe this value as a simple function of sampling variability. \n\n::: {.callout-warning}\n### What could go wrong? \n\nBefore you move on, take a minute to think about what some of the potential flaws in our CSR-based approach to assessing the meaningfulness or signficance of this result might be.\n:::\n\n# Models!\nUp to this point, we have relied on county-level summaries of the household-level radon data. For the final section of this tutorial, we are going to go back to using the full dataset and implement regression models that are able to characterize variation at the household and community level. \nSpecifcially, we are going to first fit the full-pooling, no-pooling and partial pooling models from the original @gelman2006 paper. We won't go into detail on these as they have been discussed in depth in the original paper and the previous post.  \n\n:::{.callout-note}\nNote that we are storing the residuals and predictions for each as a column inside the `radon` dataframe. \n:::\n\n:::{.callout-tip}\nFor ore detail on the implementation on interpretation of these models, please check out the [original tutorial](/posts/radon/index.html).\n:::\n\n## Full-pooling model\n\nThe full-pooling model has the following form, in which the variable $x_{ij}$ indicates whether house $i$ in county $j$ has a basement (1) or not (0).\n\n$$\ny_{ij} = \\alpha + \\beta x_{ij} + \\epsilon_{i} \n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_pooling_model <- lm(log_radon ~ basement, data = radon)\nradon$full_pooling_resid <- resid(full_pooling_model)\nradon$full_pooling_pred <- predict(full_pooling_model)\n```\n:::\n\n\n## No Pooling\n\nThe no-pooling model assumes essentially that each county is indepenedent, and includes a categorical variable for the county that the observed household is in: \n\n$$\ny_{ij} = \\alpha_j + \\beta x_{ij} + \\epsilon_{i}\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nno_pooling_model <- lm(log_radon ~ basement + county, data = radon)\nradon$no_pooling_resid <- resid(no_pooling_model)\nradon$no_pooling_pred <- predict(no_pooling_model)\n```\n:::\n\n## Partial pooling model\n\nThe partial-pooling model is the multi-level analogue to the no-pooling model. For more detail, please see the [partial pooling section](/posts/radon/index.html#sec-partial) of the original tutorial.\n\n\n::: {.cell hash='index_cache/html/partial-pool-model_3722f31c378bf97c0e3aa8a72c366b10'}\n\n```{.r .cell-code}\npartial_pool_model <- stan_lmer(log_radon ~ basement + log_uranium + (1 | county),\n    data = radon)\nradon$partial_pooling_resid <- resid(partial_pool_model)\nradon$partial_pooling_pred <- posterior_predict(partial_pool_model) %>%\n    apply(2, mean)\n```\n:::\n\n\n# Residual Analysis\n\nOne thing that is important to note is that none of the regression models we are looking at directly account for spatial clustering. In other words, the spatial arrangement of the counties is not an input to the model. This doesn't mean that they cannot adequately account for spatial correlation through the inclusion of key covariates, however. \n\nOne way to assess how well a model is accounting for observed and unobserved spatial hererogeneity is to examine the model *residuals* for evidence of spatial clustering, which is what we will do in this section. \n\nSince the residuals for each model are generated at the level of individual households, we will go back to working with county-level summaries of both the prediction error (residuals) and predicted household radon values: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults_by_county <- radon %>%\n    group_by(county) %>%\n    summarize(p_basement = sum(basement)/n(), full_pooling_resid = mean(full_pooling_resid),\n        no_pooling_resid = mean(no_pooling_resid), full_pooling_pred = mean(full_pooling_pred),\n        no_pooling_pred = mean(no_pooling_pred), partial_pooling_pred = mean(partial_pooling_pred),\n        partial_pooling_resid = mean(partial_pooling_resid))\nresults_by_county <- left_join(minnesota, results_by_county)\n```\n:::\n\n\n## Full Pooling Residuals\n\nWhen we look at the results of the full-pooling model, the residuals that still look pretty spatially clustered, and this is reflected in the value of Moran's I > 0:\n\n::: {.cell}\n\n```{.r .cell-code}\nmi <- round(moranFromSF(results_by_county$full_pooling_resid, results_by_county),\n    2)\ng <- ggplot(results_by_county) + geom_sf(aes(fill = full_pooling_resid)) + scale_fill_viridis_c() +\n    ggtitle(paste0(\"Full pooling residuals with I=\", mi))\nplot(g)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/residual-figure-1.png){width=672}\n:::\n:::\n\n\nThis is probably intuitive: the full pooling modeldidn't include any county-level information, so it might not account for all of the sptial variation. So, on the flipside, if we look at the predictions of the model - reflecting the expected household levels of radon in each county - should we should expect to find that they are spatially un-clustered or also clustered?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmi <- round(moranFromSF(results_by_county$full_pooling_pred, results_by_county),\n    2)\ng <- ggplot(results_by_county) + geom_sf(aes(fill = full_pooling_pred)) + scale_fill_viridis_c() +\n    ggtitle(paste0(\"Full pooling predictions with I=\", mi))\nplot(g)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/pred-figure-1.png){width=672}\n:::\n:::\n\n\nWait - what? The predictions are also quite clustered, although the pattern looks a bit like a photographic negative of the residual map. It looks like our model is predicting lower values in the northwest corner of the state relative to the rest of the state. How is this possible, if our model doesn't include contextual information?\n\nThis might be explained by differences in *composition* at the county level: maybe houses in some counties are more likely to have basements than in others? If this is the case, then those high-basement counties may have higher avg. levels of radon. So, lets just check and see if our one predictor - the presence or absence of a basement - exhibits any spatial variability?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmi <- round(moranFromSF(results_by_county$p_basement, results_by_county), 2)\ng <- ggplot(results_by_county) + geom_sf(aes(fill = p_basement)) + scale_fill_viridis_c() +\n    ggtitle(paste0(\"Proportion of surveyed households with a basement, I=\", mi))\nplot(g)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/basement-figure-1.png){width=672}\n:::\n:::\n\n\nWhoops...that looks familiar! It seems like the pattern of spatial variation in the presence/absence of basements may be driving the clustering in our predictions and - by consequence - our residuals!\n\n:::{.callout-tip}\n## Spatially correlated predictors → Spatially correlated predictions\n\nSometimes, it is easy to forget that the input data may be as or more correlated than the outcome data. In this example, the presence or absence of a basement in a house seems to have a spatial pattern and this impacts the spatial patterning of our predictions and model residuals!\n\n:::\n\nSo it looks like we are over-predicting risk in some areas where more surveyed households have basements and under-predicting it in other places where fewer households have basements. \n\n\n## No Pooling\n\nOk, so lets try this again with our no-pooling model which at least includes the counties as categorical covariates. Unless something weird is going on, this model should do a good job of explaining spatial variation: \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmi <- round(moranFromSF(results_by_county$no_pooling_resid, results_by_county), 2)\ng <- ggplot(results_by_county) + geom_sf(aes(fill = no_pooling_resid)) + scale_fill_viridis_c() +\n    ggtitle(paste0(\"No pooling residuals with I=\", mi))\nplot(g)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/no-pool-residual-figure-1.png){width=672}\n:::\n:::\n\n\nWell, that's a bit better, although it does such a good job at explaining away the overall variability in our measurments, we might be concerned that it is overfitting the model through the inclusion of the county level random effects. This is evidenced in the tiny size of the residuals and their minimal variation:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ng <- ggplot() + geom_histogram(aes(x = results_by_county$no_pooling_resid))\nplot(g)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/no-pool-resid-hist-1.png){width=672}\n:::\n:::\n\n\nUnsurprisingly, this model does an excellent job of predicting the spatial patterns in the original data:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmi <- round(moranFromSF(results_by_county$no_pooling_pred, results_by_county), 2)\ng <- ggplot(results_by_county) + geom_sf(aes(fill = no_pooling_pred)) + scale_fill_viridis_c() +\n    ggtitle(paste0(\"No pooling predictions with I=\", mi))\nplot(g)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/no-pool-predictions-1.png){width=672}\n:::\n:::\n\n\nI love this model! It's perfect! It captures almost the exact same clustering and spatial patterning of risk as the original data.\n\n:::{.callout-warning}\n## Danger!\n\nWhat is problematic about this model? What limits its usefulness for both interpretation and prediction?\n:::\n\n## Partial Pooling\n\nWhen we look at the predictions of the partial pooling model, they are notably smoother and more clustered than those of the full- and no-pooling models:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmi <- round(moranFromSF(results_by_county$partial_pooling_pred, results_by_county),\n    2)\ng <- ggplot(results_by_county) + geom_sf(aes(fill = partial_pooling_pred)) + scale_fill_viridis_c() +\n    ggtitle(paste0(\"Partial pooling predictions with I=\", mi))\nplot(g)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/partial-pool-pred-figure-1.png){width=672}\n:::\n:::\n\n\nIf we compare this pattern and intensity of clustering to the log-uranium data, it is clear that the smoothness in the model predictions reflects the relative smoothness and clustering of the soil uranium data: \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmi <- round(moranFromSF(minnesota_radon$log_uranium, minnesota_radon), 2)\ng <- ggplot(minnesota_radon) + geom_sf(aes(fill = log_uranium)) + scale_fill_viridis_c() +\n    ggtitle(paste0(\"Soil uranium by MN county (I = \", mi, \")\"))\nplot(g)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\nWhen we look at the residuals, they are still quite un-clustered - similar to the no pooling model, but their magnitude is larger, suggesting that the multi-level model is less suceptible to overfitting:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmi <- round(moranFromSF(results_by_county$partial_pooling_resid, results_by_county),\n    2)\ng <- ggplot(results_by_county) + geom_sf(aes(fill = partial_pooling_resid)) + scale_fill_viridis_c() +\n    ggtitle(paste0(\"Partial pooling residuals with I=\", mi))\nplot(g)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/partial-pool-residual-figure-1.png){width=672}\n:::\n:::\n\n\nBy contrast, the aggregated residuals at the county level are less indicative of overfitting than the no-pooling model, but are still a bit fat-tailed, suggesting that some counties may still be over- or under-fit.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ng <- ggplot() + geom_histogram(aes(x = results_by_county$partial_pooling_resid))\nplot(g)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/partial-pool-resid-hist-1.png){width=672}\n:::\n:::\n\n\n# What's next?\n\nIn this tutorial, we have thoroughly reviewed the spatial implications of the three types of models reviewed in the @gelman2006 analysis of household-level radon in Minnesota. While our results suggest that the partial-pooling model provides the most compelling explanation of spatial variability in our data, we are not done yet! In the next tutorial, we will look specifically at the predictive capabilities of each of these models and use the ability to predict risk for counties in which household-level measures are unavaialble or missing as the final guide in our odyssey of model comparison. ",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}