{"title":"Numerical grades as engines of inequality","markdown":{"yaml":{"title":"Numerical grades as engines of inequality","author":[{"name":"Jon Zelner","affiliation":"Dept. of Epidemiology, University of Michigan School of Public Health","url":"epibayes.io"},{"name":"Sarah Zelner","affiliation":"Instructional Services, University of Michigan School of Public Health"}],"format":"pdf","pdf-engine":"xelatex","bibliography":"references.bib","csl":"../../../assets/american-journal-of-epidemiology.csl"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\n\nIn a recent post on the blog *Grading for Growth*, Talbert [@talbert2022] argues against the use of numerical grades resulting from averaging assignment grades as a kind of category error: Rather than being numerical measurements like ones for mass, height, etc., grades are actually categories with a numerical label. These categories are ordinal, i.e. their ordering has some inherent meaning, but taking the sum or mean of the *labels* used doesn't necessarily convey useful information. In other words, most of the summary statistics we use to aggregate assignment scores have no inherent meaning in the same way that the average height of a group of people or some other summary of numerical measurements might have.\n\nThe other thing that these types of summaries do is that they typically ignore improvement over time, which of course suggests growth and effort on the part of students. As a result, a student who gets a very low grade on the first assigment of the term but a nearly perfect one on the final paper may get the same final grade as a student who is posting mediocre grades all term but exhibits essentially no improvement.\n\nThese systems necessarily advantage students who come in with a high baseline of knowledge and comfort in the classroom while disadvantaging those who may come in with a lower level of preparedness but exhibit marked improvement over the course of the term.\n\nIn this paper, we examine the imapct of different classical and progressive grading schemes on inequity in end of term outcomes. We begin with the baseline assumption that end-of-term grades should reflect growth over the course of the term rather than baseline preparedness and comfort. To assess the impact of grading schemes on inequity, we will examine the relationship between the distribution of end-of-term grades as compared to the distribution of a) beginning of term preparedness and b) individual rates of improvement over the course of the term. Grading schemes that promote equity will result in an essentially linear relationship between individual improvement and end-of-term grade, whereas those that promote inequity will largely reflect variation owing to beginning-of-term attributes rather than growth.\n\n# Methods\n\nWe will utilize a model of student knowledge and assessment performance that is analogous to a logistic regression model. We will begin with the simplifying assumption that assignment grades are perfect measures of performance, i.e. they are error-free measurements. Later on, we will complicate the notion of grades-as-measurement by including a relationship between beginning-of-term preparedness and measurement error. But beginning with this simple scenario will allow us to explore the implications of different schemes for grade inequity under even those scenarios in which assignment grades are decided upon without social bias.\n\n## Simulation Model\n\nEach student has an individual beginning-of-term expected performance, denoted as $100*(1-e^{-\\alpha_i})$ and a semester log-improvement ratio denoted as $\\beta_i$. Values are multiplied by 100 to allow outcomes to be measured on the classical 0-100 grading scale. We assume that time is measured relative to the beginning of the term, so that $t=0$ represents the first day and $t=1$ represents the last day. \n\n## Grading Scenarios\n\n```{r}\n#| echo: false\n#| warning: false\n\nrbvn<-function (n, m1, s1, m2, s2, rho)\n  {\n     X1 <- rnorm(n, m1, s1)\n     X2 <- rnorm(n, m2 + (s2/s1) * rho *\n           (X1 - m1), sqrt((1 - rho^2)*s2^2))\n     cbind(X1, X2)\n  }\n\n\n\nlibrary(dplyr)\nN <- 1000\na <- rbvn(N, 85, 1, 5, 1, -0.5)\n### Sample starting grades\na_i <- a[,1] \nz_i <- a[,2] + a[,1]\nb_i <- z_i-a_i\ny_0 <- a_i\ndf0 <- data.frame(t=0, id = 1:N, y=y_0)\ny_1 <- a_i + b_i*0.25\ndf1 <- data.frame(t=1, id = 1:N, y=y_1)\ny_2 <- a_i + b_i*0.5\ndf2 <- data.frame(t=2, id = 1:N, y=y_2)\ny_3 <- a_i + b_i*0.75\ndf3 <- data.frame(t=3, id = 1:N, y=y_3)\ny_4 <- a_i + b_i\ndf4 <- data.frame(t=4, id = 1:N, y=y_4)\n\ngrade_df <- rbind(df0, df1, df2, df3, df4)\nind_df <- data.frame(id = 1:N, a = a_i, b = b_i)\ndf <- dplyr::inner_join(ind_df, grade_df)\nhist(y_0)\n```\n\n```{r}\n#| echo: false\n#| warning: false\nhist(y_4)\nhist(b_i)\n```\n\n```{r}\n#| echo: false\n#| warning: false\nweights <- data.frame(t = 1:4, w = c(0.25, 0.25, 0.25, 0.25))\n\nfinal_grade <- df %>% \ninner_join(weights) %>%\ngroup_by(id) %>%\nsummarize(grade = sum(w*y)) %>%\ninner_join(ind_df) %>%\nmutate(grade_rank = rank(grade),\nstart_rank = rank(a),\nchange_rank = rank(b))\n\nm <- lm(grade_rank ~  change_rank, data=final_grade)\nplot(final_grade$change_rank, final_grade$grade_rank)\nplot(final_grade$start_rank, final_grade$grade_rank)\n\nsummary(m)\n```\n# References\n\n"},"formats":{"pdf":{"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","output-file":"grading-inequity-model.pdf"},"language":{},"metadata":{"block-headings":true,"title":"Numerical grades as engines of inequality","author":[{"name":"Jon Zelner","affiliation":"Dept. of Epidemiology, University of Michigan School of Public Health","url":"epibayes.io"},{"name":"Sarah Zelner","affiliation":"Instructional Services, University of Michigan School of Public Health"}],"bibliography":["references.bib"],"csl":"../../../assets/american-journal-of-epidemiology.csl"},"extensions":{"book":{}}}}}